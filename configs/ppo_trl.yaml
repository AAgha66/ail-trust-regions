 algo: 'ppo'

 use_gail: False
 gail_experts_dir: './gail_experts/'
 gail_batch_size: 128
 gail_epoch: 5
 lr_disc: 1.0e-3
 num_trajectories: 4
 gradient_penalty: False
 spectral_norm: False
 airl_reward: False

 eps: 1.0e-5
 gamma: 0.99
 use_gae: True
 gae_lambda: 0.95
 entropy_coef: 0
 value_loss_coef: 1.0
 max_grad_norm: 0.5

 seed: 0
 cuda_deterministic: False
 num_processes: 1
 num_steps: 2048

 policy_epoch: 20

 mini_batch_size: 32
 clip_param: 0.2

 logging: True
 summary: True
 track_vf: False
 track_grad_kurtosis: True
 save_model: False
 log_interval: 2
 eval_interval: 4
 
 num_env_steps: 1.5e+6
 env_name: 'HalfCheetah-v2'
 logging_dir: './logs_ppo_rb/'
 log_dir: '/tmp/gym'
 no_cuda: True
 use_proper_time_limits: True

 gradient_clipping: False
 use_linear_lr_decay: False
 use_clipped_value_loss: False
 norm_obs: True
 norm_reward: False
 clip_obs: 1.0e+6
 clip_reward: 1.0e+6

 clip_importance_ratio: True
 use_kl_penalty: False
 use_rollback: False
 use_tr_ppo: False
 use_truly_ppo: False

 rb_alpha: 5.0
 kl_target: 0.03
 start_beta: 1.0

 use_projection: True
 lr_policy: 5.0e-5
 lr_value: 4.5e-4
 proj_type: 'w2'
 mean_bound: 0.03
 cov_bound: 0.001
 trust_region_coeff: 8.0
 entropy_schedule: 'None'
 scale_prec: True
 entropy_eq: False
 entropy_first: True
 target_entropy: 0