 algo: 'ppo'

 use_gail: False
 gail_experts_dir: './gail_experts/'
 gail_batch_size: 128
 gail_epoch: 5
 lr_disc: 1.0e-3
 num_trajectories: 4
 gradient_penalty: False
 spectral_norm: False
 airl_reward: False

 eps: 1.0e-5
 gamma: 0.99
 use_gae: True
 gae_lambda: 0.95
 entropy_coef: 0
 value_loss_coef: 1.0
 max_grad_norm: 0.5

 seed: 0
 cuda_deterministic: False
 num_processes: 1
 num_steps: 2048

 policy_epoch: 10

 mini_batch_size: 64
 clip_param: 0.2

 logging: True
 summary: True
 track_vf: False
 track_grad_kurtosis: True
 save_model: False
 log_interval: 2
 eval_interval: 4
 
 num_env_steps: 1.0e+6
 env_name: 'HalfCheetah-v2'
 logging_dir: './logs_ppo/'
 log_dir: '/tmp/gym/'
 no_cuda: True
 use_proper_time_limits: True

 gradient_clipping: True
 use_linear_lr_decay: True
 use_clipped_value_loss: True
 norm_obs: True
 norm_reward: True
 clip_obs: 10.0
 clip_reward: 10.0
 lr_policy: 3.0e-4
 lr_value: 3.0e-4

 clip_importance_ratio: True
 use_kl_penalty: False
 use_rollback: False
 use_tr_ppo: False
 use_truly_ppo: False
 use_gmom: False

 rb_alpha: 5.0
 kl_target: 0.03
 start_beta: 1.0

 use_projection: False
 proj_type: 'None'
 mean_bound: 00
 cov_bound: 0
 trust_region_coeff: 0
 entropy_schedule: 'None'
 scale_prec: True
 entropy_eq: False
 entropy_first: True
 target_entropy: 0